{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f46d82a",
   "metadata": {
    "id": "4f46d82a"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "TOv9QBbeSpuR",
   "metadata": {
    "id": "TOv9QBbeSpuR"
   },
   "source": [
    "1. Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hlMt72xjStok",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlMt72xjStok",
    "outputId": "7aef1c49-3c45-47ac-ee15-ab7f84d5a043"
   },
   "outputs": [],
   "source": [
    "!pip install -q trafilatura\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9900e7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T18:17:15.332053Z",
     "start_time": "2022-04-26T18:17:15.161569Z"
    },
    "id": "c9900e7d"
   },
   "source": [
    "### 1. Task: Trafilatura\n",
    "\n",
    "On https://www.voicesofyouth.org/blog young people between the ages of 13 and 24 write blog posts for Unicef about issues they care about. We will use this blog to practice crawling and extracting html data with <i>Trafilatura</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1047aa1",
   "metadata": {
    "id": "b1047aa1"
   },
   "source": [
    "**1\\. Download the html of a single blog post and extract its data into xml format. Play with the options you learned about in the session.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d2ef29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "43d2ef29",
    "outputId": "fa49cd33-a4a0-4eaa-82cd-baec22276b49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "import trafilatura\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490d3e5b",
   "metadata": {
    "id": "490d3e5b"
   },
   "outputs": [],
   "source": [
    "url = \"https://www.voicesofyouth.org/blog/export-waste-how-it-exacerbates-global-inequalities-and-counterintuitive-fight-climate-action\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986ff177",
   "metadata": {
    "id": "986ff177"
   },
   "outputs": [],
   "source": [
    "from trafilatura.spider import focused_crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e636d91",
   "metadata": {
    "id": "2e636d91"
   },
   "outputs": [],
   "source": [
    "homepage = \"https://www.voicesofyouth.org/blog\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f994e",
   "metadata": {
    "id": "5e2f994e"
   },
   "source": [
    "<br><br>\n",
    "### 2. Task: Data analysis and visualisation\n",
    "\n",
    "In this task we will recap the most basic visualisation methods for corpus frequency distributions with the Python package <i>Plotly</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061cba4e",
   "metadata": {
    "id": "061cba4e"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import spacy\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0ad5bf",
   "metadata": {
    "id": "dc0ad5bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we load the corpus into our notebook and transform the data into a dict data structure\n",
    "corpus = Path(\"../nexis_corpus\").rglob(\"*.xml\")\n",
    "\n",
    "articles = []\n",
    "for newspaper in corpus:\n",
    "    xml_tree = ET.parse(str(newspaper))\n",
    "    doc_elements = xml_tree.findall(\"document\")\n",
    "    \n",
    "    for doc in doc_elements:\n",
    "        articles.append(\n",
    "            {\n",
    "                \"newspaper\": doc.find(\"metadata/source\").text,\n",
    "                \"text\": \" \".join([paragraph.strip() for paragraph in doc.find(\"text\").itertext()]).strip(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "articles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6672a51",
   "metadata": {
    "id": "b6672a51"
   },
   "source": [
    "<br/><br/>\n",
    "**1\\. Annotate the loaded corpus with spaCy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75950dd9",
   "metadata": {
    "id": "75950dd9"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619ced9",
   "metadata": {
    "id": "9619ced9"
   },
   "source": [
    "<br/><br/>\n",
    "**2\\. Now compile a frequency list and plot it as Zipf distribution as shown in the session - please refer to the <u>token</u> level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0835955e",
   "metadata": {
    "id": "0835955e"
   },
   "outputs": [],
   "source": [
    "tokens = [token for article in articles for token in article[\"tagged\"] if not token.is_space]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61febc9",
   "metadata": {
    "id": "e61febc9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85ce9135",
   "metadata": {
    "id": "85ce9135"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
